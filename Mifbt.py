
# -*- coding: utf-8 -*-
"""Untitled20.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WFQwrbFwz-mqGISnoaUIrY1E0AL-4HW-
"""

import os
import ast
from datetime import datetime
from flask import Flask, render_template, request, url_for
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm
try:
    import cv2
except Exception as e:
    raise ImportError("cv2 (opencv-python) is required. Install with `pip install opencv-python`. Original error: " + str(e))
import imageio
import scipy.ndimage as ndi
import argparse
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision.models.vgg import vgg19
import pywt
import pywt.data
from skimage.morphology import extrema
from skimage.segmentation import watershed as skwater

app = Flask(__name__)
APP_ROOT = app.root_path

def convertToIntList(arr):
    if isinstance(arr, list):
        return arr
    try:
        data = ast.literal_eval(arr)
    except Exception:
        s = arr.strip()
        s = s.replace('],[', '];[')
        parts = [p.strip('[]') for p in s.split(';') if p.strip()]
        out = []
        for p in parts:
            nums = [int(x) for x in p.split(',') if x.strip()]
            out.append(nums)
        return out
    return [[int(i) for i in sub] for sub in data]

def procrustes(X, Y, scaling=True, reflection='best'):
    X = np.asarray(X, dtype=np.float64)
    Y = np.asarray(Y, dtype=np.float64)
    n,m = X.shape
    ny,my = Y.shape
    muX = X.mean(0)
    muY = Y.mean(0)
    X0 = X - muX
    Y0 = Y - muY
    ssX = (X0**2.).sum()
    ssY = (Y0**2.).sum()
    normX = np.sqrt(ssX)
    normY = np.sqrt(ssY)
    X0 /= normX
    Y0 /= normY
    if my < m:
        Y0 = np.concatenate((Y0, np.zeros((n, m-my))), axis=1)
    A = np.dot(X0.T, Y0)
    U,s,Vt = np.linalg.svd(A, full_matrices=False)
    V = Vt.T
    T = np.dot(V, U.T)
    if reflection != 'best':
        have_reflection = np.linalg.det(T) < 0
        if reflection != have_reflection:
            V[:,-1] *= -1
            s[-1] *= -1
            T = np.dot(V, U.T)
    traceTA = s.sum()
    if scaling:
        b = traceTA * normX / normY
        d = 1 - traceTA**2
        Z = normX * traceTA * np.dot(Y0, T) + muX
    else:
        b = 1
        d = 1 + ssY/ssX - 2 * traceTA * normY / normX
        Z = normY * np.dot(Y0, T) + muX
    if my < m:
        T = T[:my,:]
    c = muX - b * np.dot(muY, T)
    tform = {'rotation':T, 'scale':b, 'translation':c}
    return d, Z, tform

class VGG19(torch.nn.Module):
    def __init__(self, device='cpu'):
        super(VGG19, self).__init__()
        features = list(vgg19(pretrained=True).features)
        if device == "cuda":
            self.features = nn.ModuleList(features).cuda().eval()
        else:
            self.features = nn.ModuleList(features).eval()
    def forward(self, x):
        feature_maps = []
        for idx, layer in enumerate(self.features):
            x = layer(x)
            if idx == 3:
                feature_maps.append(x)
        return feature_maps

class Fusion:
    def __init__(self, input):
        self.input_images = input
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = VGG19(self.device)
    def fuse(self):
        self.normalized_images = [-1 for _ in self.input_images]
        self.YCbCr_images = [-1 for _ in self.input_images]
        for idx, img in enumerate(self.input_images):
            if not self._is_gray(img):
                self.YCbCr_images[idx] = self._RGB_to_YCbCr(img)
                self.normalized_images[idx] = self.YCbCr_images[idx][:, :, 0]
            else:
                self.normalized_images[idx] = img / 255.
        self._tranfer_to_tensor()
        fused_img = self._fuse()[:, :, 0]
        for idx, img in enumerate(self.input_images):
            if not self._is_gray(img):
                self.YCbCr_images[idx][:, :, 0] = fused_img
                fused_img = self._YCbCr_to_RGB(self.YCbCr_images[idx])
                fused_img = np.clip(fused_img, 0, 1)
        return (fused_img * 255).astype(np.uint8)
    def _fuse(self):
        with torch.no_grad():
            imgs_sum_maps = [-1 for _ in self.images_to_tensors]
            for idx, tensor_img in enumerate(self.images_to_tensors):
                imgs_sum_maps[idx] = []
                feature_maps = self.model(tensor_img)
                for feature_map in feature_maps:
                    sum_map = torch.sum(feature_map, dim=1, keepdim=True)
                    imgs_sum_maps[idx].append(sum_map)
            max_fusion = None
            for sum_maps in zip(*imgs_sum_maps):
                features = torch.cat(sum_maps, dim=1)
                weights = self._softmax(F.interpolate(features, size=self.images_to_tensors[0].shape[2:]))
                weights = F.interpolate(weights, size=self.images_to_tensors[0].shape[2:])
                current_fusion = torch.zeros(self.images_to_tensors[0].shape)
                for idx, tensor_img in enumerate(self.images_to_tensors):
                    current_fusion += tensor_img * weights[:,idx]
                if max_fusion is None:
                    max_fusion = current_fusion
                else:
                    max_fusion = torch.max(max_fusion, current_fusion)
            output = np.squeeze(max_fusion.cpu().numpy())
            if output.ndim == 3:
                output = np.transpose(output, (1, 2, 0))
            return output
    def _RGB_to_YCbCr(self, img_RGB):
        img_RGB = img_RGB.astype(np.float32) / 255.
        return cv2.cvtColor(img_RGB, cv2.COLOR_RGB2YCrCb)
    def _YCbCr_to_RGB(self, img_YCbCr):
        img_YCbCr = img_YCbCr.astype(np.float32)
        return cv2.cvtColor(img_YCbCr, cv2.COLOR_YCrCb2RGB)
    def _is_gray(self, img):
        if len(img.shape) < 3:
            return True
        if img.shape[2] == 1:
            return True
        b,g,r = img[:,:,0], img[:,:,1], img[:,:,2]
        if (b == g).all() and (b == r).all():
            return True
        return False
    def _softmax(self, tensor):
        tensor = torch.exp(tensor)
        tensor = tensor / tensor.sum(dim=1, keepdim=True)
        return tensor
    def _tranfer_to_tensor(self):
        self.images_to_tensors = []
        for image in self.normalized_images:
            np_input = image.astype(np.float32)
            if np_input.ndim == 2:
                H,W = np_input.shape
                np_input = np_input.reshape(1,1,H,W)
                np_input = np.repeat(np_input, 3, axis=1)
            else:
                np_input = np.transpose(np_input, (2,0,1))[None]
            tensor = torch.from_numpy(np_input)
            if self.device == "cuda":
                tensor = tensor.cuda()
            self.images_to_tensors.append(tensor)

@app.route("/")
def index():
    return render_template("form.html")

@app.route("/upload", methods=['POST'])
def upload():
    target = os.path.join(APP_ROOT, 'static')
    if not os.path.isdir(target):
        os.mkdir(target)
    mri_file = request.files.get('mri')
    ct_file = request.files.get('ct')
    if not mri_file or not ct_file:
        return "Missing files", 400
    destination1 = os.path.join(target, "mri.jpg")
    mri_file.save(destination1)
    destination2 = os.path.join(target, "ct.jpg")
    ct_file.save(destination2)
    points = request.form.get("points","0")
    return render_template("registration.html", points=points)

@app.route("/register", methods=['POST'])
def register():
    mriCoord = convertToIntList(request.form.get('mriCoord','[]'))
    ctCoord = convertToIntList(request.form.get('ctCoord','[]'))
    ct = cv2.imread(os.path.join('static','ct.jpg'), 0)
    mri = cv2.imread(os.path.join('static','mri.jpg'), 0)
    if ct is None or mri is None:
        return "Images not found", 400
    X_pts = np.asarray(ctCoord)
    Y_pts = np.asarray(mriCoord)
    d,Z_pts,Tform = procrustes(X_pts,Y_pts)
    R = np.eye(3)
    R[0:2,0:2] = Tform['rotation']
    S = np.eye(3) * Tform['scale']
    S[2,2] = 1
    t = np.eye(3)
    t[0:2,2] = Tform['translation']
    M = np.dot(np.dot(R,S),t.T).T
    h = ct.shape[1]
    w = ct.shape[0]
    tr_Y_img = cv2.warpAffine(mri, M[0:2,:], (h, w))
    cv2.imwrite(os.path.join('static','mri_registered.jpg'), tr_Y_img)
    return "registered"

@app.route("/registerimage")
def registerimage():
    return render_template("imageregistration.html")

@app.route("/fusion")
def fusion():
    mri_image = cv2.imread(os.path.join('static','mri_registered.jpg'))
    if mri_image is None:
        return "Registered MRI not found", 400
    mri_image = cv2.cvtColor(mri_image, cv2.COLOR_BGR2GRAY)
    coeffs2 = pywt.dwt2(mri_image, 'haar')
    LL, (LH, HL, HH) = coeffs2
    for i, a in enumerate([LL, LH, HL, HH]):
        path = os.path.join('static', f'mri_{i}.jpg')
        cv2.imwrite(path, a.astype(np.uint8))
    ct_image = cv2.imread(os.path.join('static','ct.jpg'))
    if ct_image is None:
        return "CT not found", 400
    ct_image = cv2.cvtColor(ct_image, cv2.COLOR_BGR2GRAY)
    coeffs2 = pywt.dwt2(ct_image, 'haar')
    LL, (LH, HL, HH) = coeffs2
    for i, a in enumerate([LL, LH, HL, HH]):
        path = os.path.join('static', f'ct_{i}.jpg')
        cv2.imwrite(path, a.astype(np.uint8))
    def do_fuse(mri_path, ct_path, out_path):
        mri = cv2.imread(mri_path)
        mri = cv2.cvtColor(mri, cv2.COLOR_BGR2GRAY)
        ct = cv2.imread(ct_path)
        ct = cv2.cvtColor(ct, cv2.COLOR_BGR2GRAY)
        input_images = [mri, ct]
        FU = Fusion(input_images)
        fusion_img = FU.fuse()
        cv2.imwrite(out_path, fusion_img)
    do_fuse(os.path.join('static','mri_0.jpg'), os.path.join('static','ct_0.jpg'), os.path.join('static','fusion_0.jpg'))
    do_fuse(os.path.join('static','mri_1.jpg'), os.path.join('static','ct_1.jpg'), os.path.join('static','fusion_1.jpg'))
    do_fuse(os.path.join('static','mri_2.jpg'), os.path.join('static','ct_2.jpg'), os.path.join('static','fusion_2.jpg'))
    do_fuse(os.path.join('static','mri_3.jpg'), os.path.join('static','ct_3.jpg'), os.path.join('static','fusion_3.jpg'))
    fusion_0 = cv2.imread(os.path.join('static','fusion_0.jpg'), 0)
    fusion_1 = cv2.imread(os.path.join('static','fusion_1.jpg'), 0)
    fusion_2 = cv2.imread(os.path.join('static','fusion_2.jpg'), 0)
    fusion_3 = cv2.imread(os.path.join('static','fusion_3.jpg'), 0)
    coeffs = (fusion_0, (fusion_1, fusion_2, fusion_3))
    fusion = pywt.idwt2(coeffs, 'haar')
    cv2.imwrite(os.path.join('static','fusion.jpg'), fusion.astype(np.uint8))
    return render_template("fusion.html")

@app.route("/segmentation")
def segmentation():
    img = cv2.imread(os.path.join('static','fusion.jpg'))
    if img is None:
        return "Fusion image not found", 400
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_OTSU)
    ret, markers = cv2.connectedComponents(thresh)
    marker_area = [np.sum(markers==m) for m in range(1, np.max(markers)+1)]
    if not marker_area:
        return "No components", 400
    largest_component = np.argmax(marker_area) + 1
    brain_mask = markers == largest_component
    brain_out = img.copy()
    brain_out[~brain_mask] = (0,0,0)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)
    kernel = np.ones((3,3),np.uint8)
    opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)
    sure_bg = cv2.dilate(opening,kernel,iterations=3)
    dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)
    ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)
    sure_fg = np.uint8(sure_fg)
    unknown = cv2.subtract(sure_bg,sure_fg)
    ret, markers = cv2.connectedComponents(sure_fg)
    markers = markers + 1
    markers[unknown==255] = 0
    markers = cv2.watershed(img, markers)
    img[markers == -1] = [255,0,0]
    im1 = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)
    cv2.imwrite(os.path.join('static','segmented.jpg'), im1)
    return render_template("segmentation.html")

@app.after_request
def add_header(response):
    response.headers['Pragma'] = 'no-cache'
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    response.headers['Expires'] = '0'
    return response

if __name__ == "__main__":
    app.run(debug=True)